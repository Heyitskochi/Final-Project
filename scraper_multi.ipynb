{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "from splinter import Browser\n",
    "import os\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 92.0.4515\n",
      "Get LATEST driver version for 92.0.4515\n",
      "Driver [C:\\Users\\SC\\.wdm\\drivers\\chromedriver\\win32\\92.0.4515.107\\chromedriver.exe] found in cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.indeed.com/jobs?q=data%20analyst&l=California&start=0\n",
      "http://www.indeed.com/jobs?q=data%20analyst&l=California&start=10\n"
     ]
    }
   ],
   "source": [
    "executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "browser = Browser('chrome', **executable_path, headless=False)\n",
    "\n",
    "max_page = 100\n",
    "\n",
    "for start in range(0, max_page, 10):\n",
    "    indeed_url = 'http://www.indeed.com/jobs?q=data%20analyst&l=California&start=' + str(start)\n",
    "    browser.visit(indeed_url)\n",
    "    time.sleep(2)  \n",
    "    html = browser.html\n",
    "    soup = bs(html, \"html.parser\")\n",
    "    print(indeed_url)\n",
    "    \n",
    "    jobs = []\n",
    "    companies = []\n",
    "    locations = []\n",
    "    summaries = []  \n",
    "    \n",
    "    for div in soup.find_all(name='div', attrs={'class':'job_seen_beacon'}):\n",
    "\n",
    "        #grabbing job title\n",
    "        for td in soup.find_all(name='td', attrs={'class':'resultContent'}):\n",
    "            for div in td.find_all(name='div', attrs={'class':'heading4 color-text-primary singleLineTitle tapItem-gutter'}):\n",
    "                for span in div.find_all(name='span'):\n",
    "                    if span.text.strip() != 'new':\n",
    "                        jobs.append(span.text.strip())  \n",
    "\n",
    "        #grabbing company name\n",
    "        for td in soup.find_all(name='td', attrs={'class':'resultContent'}):\n",
    "            for div in td.find_all(name='div', attrs={'class':'heading6 company_location tapItem-gutter'}):\n",
    "                for span in div.find_all(name='span', attrs={'class':'companyName'}):\n",
    "                    companies.append(span.text.strip())      \n",
    "\n",
    "        #grabbing location\n",
    "        for td in soup.find_all(name='td', attrs={'class':'resultContent'}):\n",
    "            for div in td.find_all(name='div', attrs={'class':'heading6 company_location tapItem-gutter'}):\n",
    "                for div in div.find_all(name='div'):\n",
    "                    locations.append(div.text.strip())   \n",
    "\n",
    "        #grabbing summary text\n",
    "        divs = soup.findAll('div', attrs={'class': 'job-snippet'})\n",
    "        for div in divs:\n",
    "            summaries.append(div.text.strip())\n",
    "\n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_list_max_df = pd.DataFrame(list(zip(jobs, companies, locations, summaries)),\n",
    "               columns = ['job_title', 'company_name', 'location', 'summary'])\n",
    "job_list_max_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_list_max_df.to_csv('job_list_multi.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
