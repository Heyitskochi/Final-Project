{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Find the latest version of spark 3.0  from http://www-us.apache.org/dist/spark/ and enter as the spark version\n",
    "# For example:\n",
    "# spark_version = 'spark-3.0.2'\n",
    "spark_version = 'spark-3.<enter version>'\n",
    "os.environ['SPARK_VERSION']=spark_version\n",
    "\n",
    "# Install Spark and Java\n",
    "!apt-get update\n",
    "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
    "!wget -q http://www-us.apache.org/dist/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop2.7.tgz\n",
    "!tar xf $SPARK_VERSION-bin-hadoop2.7.tgz\n",
    "!pip install -q findspark\n",
    "\n",
    "# Set Environment Variables\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
    "os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop2.7\"\n",
    "\n",
    "# Start a SparkSession\n",
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start Spark session\n",
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"Hashing\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\ckkoc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ckkoc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ckkoc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer, StopWordsRemover\n",
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from  itertools import chain\n",
    "import numpy as np\n",
    "import ast as ast\n",
    "import string\n",
    "import re\n",
    "import warnings\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "stopword = nltk.corpus.stopwords.words(\"english\")\n",
    "ps = nltk.PorterStemmer()\n",
    "wn = nltk.WordNetLemmatizer()\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "|           job_title|        company_name|            location|             summary|\n",
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "|       Data Engineer| Synaptein Solutions|   Thousand Oaks. CA|Proven proficienc...|\n",
      "|   Data Engineer III|               Ursus|Menlo Park. CA 94...|Experience with E...|\n",
      "|       Data Engineer|             Harnham|San Francisco. CA...|Using programming...|\n",
      "|Associate. Visual...|                KPMG|Los Angeles. CA 9...|Proficient with d...|\n",
      "|Data Engineer. Gr...|              Square|   San Francisco. CA|Understand and im...|\n",
      "|   SQL Data Engineer|Thermo Fisher Sci...|  Carlsbad. CA 92008|Understand variou...|\n",
      "|       Data Engineer|               Navis|         Oakland. CA|Developing data i...|\n",
      "|       Data Engineer|      Deckers Brands|    Goleta. CA 93117|Create data pipel...|\n",
      "|Data Visualizatio...|Unicorn Technolog...|Oakland. CA•Tempo...|Experience defini...|\n",
      "|       Data Engineer|   Kaiser Permanente|         Oakland. CA|You will transfor...|\n",
      "|Data Engineer/ETL...|          CDM search|Berkeley. CA 9470...|Troubleshoot emer...|\n",
      "|       Data Engineer|Best High technol...|San Jose. CA•Temp...|Demonstrated abil...|\n",
      "|       Data Engineer|      Yochana IT inc|San Francisco. CA...|Major skills requ...|\n",
      "|Senior Data Engineer|                Visa|     Foster City. CA|Experience with e...|\n",
      "|L3 Network Data C...|Rangam Consultant...|Menlo Park. CA•Re...|Looking for those...|\n",
      "|Senior Data Engineer|                Visa|     Foster City. CA|Experience with e...|\n",
      "|L3 Network Data C...|Rangam Consultant...|Menlo Park. CA•Re...|Looking for those...|\n",
      "|Entry Level - Dat...|     PCS Global Tech|Poway. CA•Tempora...|Provides plan wit...|\n",
      "|       Data Engineer|                Hive|   San Francisco. CA|Building out our ...|\n",
      "|Data Engineer (10...|City and County o...|San Francisco. CA...|We work to stream...|\n",
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Import CSV into Data\n",
    "file_path = \"job_list_engineer.csv\"\n",
    "csv_df = spark.read.csv(path=file_path, sep=\",\", header=True)\n",
    "csv_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|           job_title|        company_name|            location|             summary|              tokens|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|       Data Engineer| Synaptein Solutions|   Thousand Oaks. CA|Proven proficienc...|[proven, proficie...|\n",
      "|   Data Engineer III|               Ursus|Menlo Park. CA 94...|Experience with E...|[experience, with...|\n",
      "|       Data Engineer|             Harnham|San Francisco. CA...|Using programming...|[using, programmi...|\n",
      "|Associate. Visual...|                KPMG|Los Angeles. CA 9...|Proficient with d...|[proficient, with...|\n",
      "|Data Engineer. Gr...|              Square|   San Francisco. CA|Understand and im...|[understand, and,...|\n",
      "|   SQL Data Engineer|Thermo Fisher Sci...|  Carlsbad. CA 92008|Understand variou...|[understand, vari...|\n",
      "|       Data Engineer|               Navis|         Oakland. CA|Developing data i...|[developing, data...|\n",
      "|       Data Engineer|      Deckers Brands|    Goleta. CA 93117|Create data pipel...|[create, data, pi...|\n",
      "|Data Visualizatio...|Unicorn Technolog...|Oakland. CA•Tempo...|Experience defini...|[experience, defi...|\n",
      "|       Data Engineer|   Kaiser Permanente|         Oakland. CA|You will transfor...|[you, will, trans...|\n",
      "|Data Engineer/ETL...|          CDM search|Berkeley. CA 9470...|Troubleshoot emer...|[troubleshoot, em...|\n",
      "|       Data Engineer|Best High technol...|San Jose. CA•Temp...|Demonstrated abil...|[demonstrated, ab...|\n",
      "|       Data Engineer|      Yochana IT inc|San Francisco. CA...|Major skills requ...|[major, skills, r...|\n",
      "|Senior Data Engineer|                Visa|     Foster City. CA|Experience with e...|[experience, with...|\n",
      "|L3 Network Data C...|Rangam Consultant...|Menlo Park. CA•Re...|Looking for those...|[looking, for, th...|\n",
      "|Senior Data Engineer|                Visa|     Foster City. CA|Experience with e...|[experience, with...|\n",
      "|L3 Network Data C...|Rangam Consultant...|Menlo Park. CA•Re...|Looking for those...|[looking, for, th...|\n",
      "|Entry Level - Dat...|     PCS Global Tech|Poway. CA•Tempora...|Provides plan wit...|[provides, plan, ...|\n",
      "|       Data Engineer|                Hive|   San Francisco. CA|Building out our ...|[building, out, o...|\n",
      "|Data Engineer (10...|City and County o...|San Francisco. CA...|We work to stream...|[we, work, to, st...|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the words\n",
    "tokenizer = Tokenizer(inputCol=\"summary\", outputCol=\"tokens\")\n",
    "wordsData2 = tokenizer.transform(csv_df)\n",
    "wordsData2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Remover\n",
    "remover = StopWordsRemover(inputCol=\"tokens\", outputCol=\"filtered\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|           job_title|        company_name|            location|             summary|              tokens|            filtered|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|       Data Engineer| Synaptein Solutions|   Thousand Oaks. CA|Proven proficienc...|[proven, proficie...|[proven, proficie...|\n",
      "|   Data Engineer III|               Ursus|Menlo Park. CA 94...|Experience with E...|[experience, with...|[experience, etl,...|\n",
      "|       Data Engineer|             Harnham|San Francisco. CA...|Using programming...|[using, programmi...|[using, programmi...|\n",
      "|Associate. Visual...|                KPMG|Los Angeles. CA 9...|Proficient with d...|[proficient, with...|[proficient, data...|\n",
      "|Data Engineer. Gr...|              Square|   San Francisco. CA|Understand and im...|[understand, and,...|[understand, impl...|\n",
      "|   SQL Data Engineer|Thermo Fisher Sci...|  Carlsbad. CA 92008|Understand variou...|[understand, vari...|[understand, vari...|\n",
      "|       Data Engineer|               Navis|         Oakland. CA|Developing data i...|[developing, data...|[developing, data...|\n",
      "|       Data Engineer|      Deckers Brands|    Goleta. CA 93117|Create data pipel...|[create, data, pi...|[create, data, pi...|\n",
      "|Data Visualizatio...|Unicorn Technolog...|Oakland. CA•Tempo...|Experience defini...|[experience, defi...|[experience, defi...|\n",
      "|       Data Engineer|   Kaiser Permanente|         Oakland. CA|You will transfor...|[you, will, trans...|[transform, data,...|\n",
      "|Data Engineer/ETL...|          CDM search|Berkeley. CA 9470...|Troubleshoot emer...|[troubleshoot, em...|[troubleshoot, em...|\n",
      "|       Data Engineer|Best High technol...|San Jose. CA•Temp...|Demonstrated abil...|[demonstrated, ab...|[demonstrated, ab...|\n",
      "|       Data Engineer|      Yochana IT inc|San Francisco. CA...|Major skills requ...|[major, skills, r...|[major, skills, r...|\n",
      "|Senior Data Engineer|                Visa|     Foster City. CA|Experience with e...|[experience, with...|[experience, extr...|\n",
      "|L3 Network Data C...|Rangam Consultant...|Menlo Park. CA•Re...|Looking for those...|[looking, for, th...|[looking, network...|\n",
      "|Senior Data Engineer|                Visa|     Foster City. CA|Experience with e...|[experience, with...|[experience, extr...|\n",
      "|L3 Network Data C...|Rangam Consultant...|Menlo Park. CA•Re...|Looking for those...|[looking, for, th...|[looking, network...|\n",
      "|Entry Level - Dat...|     PCS Global Tech|Poway. CA•Tempora...|Provides plan wit...|[provides, plan, ...|[provides, plan, ...|\n",
      "|       Data Engineer|                Hive|   San Francisco. CA|Building out our ...|[building, out, o...|[building, data, ...|\n",
      "|Data Engineer (10...|City and County o...|San Francisco. CA...|We work to stream...|[we, work, to, st...|[work, streamline...|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Drop Stop Words\n",
    "cleaneddf = remover.transform(wordsData2)\n",
    "cleaneddf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>company_name</th>\n",
       "      <th>location</th>\n",
       "      <th>summary</th>\n",
       "      <th>tokens</th>\n",
       "      <th>filtered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Synaptein Solutions</td>\n",
       "      <td>Thousand Oaks. CA</td>\n",
       "      <td>Proven proficiency with scripting languages su...</td>\n",
       "      <td>[proven, proficiency, with, scripting, languag...</td>\n",
       "      <td>[proven, proficiency, scripting, languages, py...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Engineer III</td>\n",
       "      <td>Ursus</td>\n",
       "      <td>Menlo Park. CA 94025+1 location</td>\n",
       "      <td>Experience with ETL processes. extracting data...</td>\n",
       "      <td>[experience, with, etl, processes., extracting...</td>\n",
       "      <td>[experience, etl, processes., extracting, data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Harnham</td>\n",
       "      <td>San Francisco. CA+1 location</td>\n",
       "      <td>Using programming skills to create data pipeli...</td>\n",
       "      <td>[using, programming, skills, to, create, data,...</td>\n",
       "      <td>[using, programming, skills, create, data, pip...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Associate. Visualization Data Engineer</td>\n",
       "      <td>KPMG</td>\n",
       "      <td>Los Angeles. CA 90071 (Downtown area)</td>\n",
       "      <td>Proficient with data management and integratio...</td>\n",
       "      <td>[proficient, with, data, management, and, inte...</td>\n",
       "      <td>[proficient, data, management, integration., d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Engineer. Growth</td>\n",
       "      <td>Square</td>\n",
       "      <td>San Francisco. CA</td>\n",
       "      <td>Understand and implement data logging best pra...</td>\n",
       "      <td>[understand, and, implement, data, logging, be...</td>\n",
       "      <td>[understand, implement, data, logging, best, p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                job_title         company_name  \\\n",
       "0                           Data Engineer  Synaptein Solutions   \n",
       "1                       Data Engineer III                Ursus   \n",
       "2                           Data Engineer              Harnham   \n",
       "3  Associate. Visualization Data Engineer                 KPMG   \n",
       "4                   Data Engineer. Growth               Square   \n",
       "\n",
       "                                location  \\\n",
       "0                      Thousand Oaks. CA   \n",
       "1        Menlo Park. CA 94025+1 location   \n",
       "2           San Francisco. CA+1 location   \n",
       "3  Los Angeles. CA 90071 (Downtown area)   \n",
       "4                      San Francisco. CA   \n",
       "\n",
       "                                             summary  \\\n",
       "0  Proven proficiency with scripting languages su...   \n",
       "1  Experience with ETL processes. extracting data...   \n",
       "2  Using programming skills to create data pipeli...   \n",
       "3  Proficient with data management and integratio...   \n",
       "4  Understand and implement data logging best pra...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [proven, proficiency, with, scripting, languag...   \n",
       "1  [experience, with, etl, processes., extracting...   \n",
       "2  [using, programming, skills, to, create, data,...   \n",
       "3  [proficient, with, data, management, and, inte...   \n",
       "4  [understand, and, implement, data, logging, be...   \n",
       "\n",
       "                                            filtered  \n",
       "0  [proven, proficiency, scripting, languages, py...  \n",
       "1  [experience, etl, processes., extracting, data...  \n",
       "2  [using, programming, skills, create, data, pip...  \n",
       "3  [proficient, data, management, integration., d...  \n",
       "4  [understand, implement, data, logging, best, p...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convert to Pandas Dataframe\n",
    "pandasDF = cleaneddf.toPandas()\n",
    "pandasDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filtered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[proven, proficiency, scripting, languages, py...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[experience, etl, processes, extracting, data,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[using, programming, skills, create, data, pip...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[proficient, data, management, integration, da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[understand, implement, data, logging, best, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>[functionally, lead, team, data, engineers, de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>[server, network, hardware, troubleshooting, f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>[support, day-to-day, operations, escalations,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>[experience, relational, data, modeling, metad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>[experience, data, engineering, -, etl, pipeli...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>510 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              filtered\n",
       "0    [proven, proficiency, scripting, languages, py...\n",
       "1    [experience, etl, processes, extracting, data,...\n",
       "2    [using, programming, skills, create, data, pip...\n",
       "3    [proficient, data, management, integration, da...\n",
       "4    [understand, implement, data, logging, best, p...\n",
       "..                                                 ...\n",
       "505  [functionally, lead, team, data, engineers, de...\n",
       "506  [server, network, hardware, troubleshooting, f...\n",
       "507  [support, day-to-day, operations, escalations,...\n",
       "508  [experience, relational, data, modeling, metad...\n",
       "509  [experience, data, engineering, -, etl, pipeli...\n",
       "\n",
       "[510 rows x 1 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#turn filtered text into a dataframe\n",
    "countable =pandasDF.drop(columns = [\"job_title\", \"company_name\", \"location\", \"summary\", \"tokens\"])\n",
    "\n",
    "#remove punctuation and turn column into a list\n",
    "countable['filtered'] = countable['filtered'].astype(str)\n",
    "countable[\"filtered\"] = countable['filtered'].str.replace('(','')\n",
    "countable[\"filtered\"] = countable['filtered'].str.replace(')','')\n",
    "countable[\"filtered\"] = countable['filtered'].str.replace('?','')\n",
    "countable[\"filtered\"] = countable['filtered'].str.replace('.','')\n",
    "countable[\"filtered\"] = countable['filtered'].str.replace('/','')\n",
    "countable[\"filtered\"] = countable['filtered'].str.replace('&','')\n",
    "countable[\"filtered\"] = countable[\"filtered\"].apply(eval)\n",
    "countable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part-of-Speech and Word Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filtered</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>data</td>\n",
       "      <td>1340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>experience</td>\n",
       "      <td>236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963</th>\n",
       "      <td>pipelines</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>build</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>design</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       filtered  count\n",
       "313        data   1340\n",
       "499  experience    236\n",
       "963   pipelines    104\n",
       "176       build     80\n",
       "366      design     74"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use sortvalues to count the number of times each word appears\n",
    "a = pd.Series([item for sublist in countable.filtered for item in sublist])\n",
    "counted_df = a.value_counts().sort_index().rename_axis('filtered').reset_index(name='count')\n",
    "counted_df.sort_values(by=['count'], ascending=False, inplace=True)\n",
    "counted_df= counted_df[counted_df.filtered != \"\"]\n",
    "counted_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filtered</th>\n",
       "      <th>count</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>data</td>\n",
       "      <td>1340</td>\n",
       "      <td>NNS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>experience</td>\n",
       "      <td>236</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963</th>\n",
       "      <td>pipelines</td>\n",
       "      <td>104</td>\n",
       "      <td>NNS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>build</td>\n",
       "      <td>80</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>design</td>\n",
       "      <td>74</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       filtered  count  pos\n",
       "313        data   1340  NNS\n",
       "499  experience    236   NN\n",
       "963   pipelines    104  NNS\n",
       "176       build     80   NN\n",
       "366      design     74   NN"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counted_df['pos'] = counted_df['filtered'].apply(lambda x: nltk.pos_tag([x])[0][1])\n",
    "counted_df.to_csv('pos_count_scientist.csv', index = False)\n",
    "counted_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filtered</th>\n",
       "      <th>count</th>\n",
       "      <th>pos</th>\n",
       "      <th>stems</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>data</td>\n",
       "      <td>1340</td>\n",
       "      <td>NNS</td>\n",
       "      <td>data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>experience</td>\n",
       "      <td>236</td>\n",
       "      <td>NN</td>\n",
       "      <td>experi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963</th>\n",
       "      <td>pipelines</td>\n",
       "      <td>104</td>\n",
       "      <td>NNS</td>\n",
       "      <td>pipelin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>build</td>\n",
       "      <td>80</td>\n",
       "      <td>NN</td>\n",
       "      <td>build</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>design</td>\n",
       "      <td>74</td>\n",
       "      <td>NN</td>\n",
       "      <td>design</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       filtered  count  pos    stems\n",
       "313        data   1340  NNS     data\n",
       "499  experience    236   NN   experi\n",
       "963   pipelines    104  NNS  pipelin\n",
       "176       build     80   NN    build\n",
       "366      design     74   NN   design"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lemmatizing(tnp):\n",
    "    text = wn.lemmatize(tnp)\n",
    "    return text\n",
    "counted_df[\"lemmatize\"] = counted_df[\"filtered\"].apply(lambda x: lemmatizing(x))\n",
    "counted_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Total_Count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stems</th>\n",
       "      <th>pos</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>data</th>\n",
       "      <th>NNS</th>\n",
       "      <td>1340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experi</th>\n",
       "      <th>NN</th>\n",
       "      <td>236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>build</th>\n",
       "      <th>NN</th>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>engin</th>\n",
       "      <th>NN</th>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pipelin</th>\n",
       "      <th>NNS</th>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Total_Count\n",
       "stems   pos             \n",
       "data    NNS         1340\n",
       "experi  NN           236\n",
       "build   NN           123\n",
       "engin   NN           110\n",
       "pipelin NNS          104"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_df = counted_df.groupby([\"lemmatize\", \"pos\"]).agg({'count': [\"sum\"]})\n",
    "total_df = pd.DataFrame(total_df)\n",
    "total_df.columns = ['Total_Count']\n",
    "total_df.sort_values(by=['Total_Count'], ascending=False, inplace=True)\n",
    "total_df.to_csv('pos_count_engineer.csv')\n",
    "total_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
